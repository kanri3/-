{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Applied_Math_00.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPH7T7Zrxfkk0xy/ltCqvKc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanri3/applied_math/blob/main/Applied_Math_00.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpEhoGtA6Nzw"
      },
      "source": [
        "# 応用数学レポート\n",
        "####第1章：線形代数\n",
        "1. 固有値・固有ベクトルとは？  \n",
        "正方行列$A$に対して、以下の数式を満たす定数$\\lambda$とベクトル$\\vec{x}$のことを、それぞれ固有値・固有ベクトルと言う。  \n",
        "$$\n",
        "A\\vec{x}=\\lambda\\vec{x}\n",
        "$$\n",
        "固有ベクトル$\\vec{x}$に行列$A$を掛けても、$\\vec{x}$の方向は変わらずに、大きさだけ固有値$\\lambda$倍される。  \n",
        "$\\vec{x}$は$\\lambda$の数だけ存在する。\n",
        "1. 固有値分解とは？  \n",
        "$\\lambda$を降順で並べ替えたものを対角成分とする対角行列$\\Lambda$を作る。  \n",
        "また$\\lambda$（降順）と対応する $\\vec{x}$ を列にして行列$V$を作る。  \n",
        "すると$AV = V\\Lambda$を経て以下の数式を得るが、これを$A$の固有値分解という。\n",
        "$$\n",
        "A = V\\Lambda V^{-1} \n",
        "$$\n",
        "1. 特異値分解とは？  \n",
        "固有値分解は正方行列だけしか扱えない。これは実用上大きな制約。これを克服し、扱える範囲を正方行列以外にも拡張させたのが特異値分解である。  \n",
        "行列$X$（m行n列）の特異値分解\n",
        "$$\n",
        "X=U\\Sigma V^{T}\n",
        "$$\n",
        "$U$：正方行列（m×m）。  \n",
        "$\\Sigma$：対角行列（m×n）。対角成分に特異値を持つ。  \n",
        "$V$：正方行列（n×n）。列に特異ベクトルを並べセットしたもの。\n",
        "####第2章：確率・統計\n",
        "1. 条件付き確率とは？  \n",
        "事象X=xを前提に事象Y=yが生じる確率。  \n",
        "ここでX,Yはある「系」（サイコロ，天気etc）を表し、またx,yはその系の下で起きる事象を表す。\n",
        "1. ベイズの定理とは？  \n",
        "たとえば「ワクチン接種済みだと安心顔になる確率」が既知であるなら、ベイズの定理により「安心顔の人がワクチン接種済みである確率」を求められる。  \n",
        "（但し、「ワクチン接種済みである確率」および「安心顔である確率」も既知であること）\n",
        "1. 期待値とは？  \n",
        "いわゆる平均値。  \n",
        "確率変数と確率の積を全ての事象について合計したもの。\n",
        "1. 分散とは？  \n",
        "分散とは、データの散らばり具合を表す値である。  \n",
        "データの正負が原因で生じる相殺を回避する処理（二乗）の後、平均をとったもの。  \n",
        "1. ベルヌーイ分布\n",
        "$$\n",
        "P(X=k)=p^{k}(1-p)^{k}\n",
        "$$\n",
        "離散分布。（kの取りうる値は0か1のみ）\n",
        "####第3章：情報理論\n",
        "1. 自己情報量とは？  \n",
        "事象が発生する前後で不確かさ（エントロピー）が減少する場合、その差を自己情報量という。\n",
        "$$\n",
        "I(x)=-logP(x)\n",
        "$$\n",
        "要するに、発生する確率が低いこと（珍しいこと）が分かった時の方が、情報量が多い。\n",
        "1. 平均情報量（シャノンエントロピー）とは？  \n",
        "自己情報量の期待値である。\n",
        "$$\n",
        "H(X)=-\\Sigma \\left( P(x)logP(x) \\right)\n",
        "$$\n",
        "1. KLダイバージェンスとは？  \n",
        "２つの確率分布がどの程度似ているかを表す尺度。\n",
        "1. 交差エントロピー誤差とは？  \n",
        "機械学習で推定した確率分布が、真の確率分布に近い程小さくなる値。\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaLYu0f650X1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL2Y-377vTjE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}